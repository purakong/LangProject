LangGraph의 탄생배경

1. LLM이 생성한 답변은 Hallucination이 아닐까?
2. RAG를 적용하여 받은 답변이 문서에는 없는 "사전 지식"으로 답변한 것은 아닐까?
3. "문서 검색에서 원하는 내용이 없을 경우" -> "인터넷" 혹은 "논문"에서 부족한 정보를 검색하여 지식을 보강할 수 는 없을까?

======================================================================
만약, LangGraph가 없다고 가정해보자. 사용자가 LLM을 통해서 비스포크 냉장고를 만든 회사의 2023년 매출액을 알려줘. 라고 했을 때, LLM이 잘못된 정보를 답할수도 있다. 그렇다면 검색이 제대로 나올때까지 무한 반복을 할까? 혹은 Hallucination을 방지하는 LLM을 또 추가할까? 이런 처리 코드를 나열하다보면 코드가 복잡해지고, 중간 단계에서 잘못된 답변은 나비효과를 불러 일으킴

======================================================================
Conventional RAG의 문제점
- 사전에 정의된 데이터 소싱(PDF,DB,Table) 자원의 문제
- 사전에 정의된 Fixed Size Chunk
- 사전에 정의된 Query 입력
- 사전에 정의된 검색 방법
- 신뢰하기 어려운 LLM 혹은 Agent
- 고정된 프롬프트 형식
- LLM의 답변 결과에 대한 문서와의 관련성/신뢰성 문제
 => 즉, 잘못된 답변이 나왔을때, 어디서부터 어떻게 고쳐야할지 모른다. 청크 사이즈? 프롬프트? 즉, Conventional RAG의 파이프라인은 단방향 구조이기 때문에 한번에 모든 단계를 다 잘해야함. 즉, 이전 단계로 되돌아가기 어렵고, 한 곳에 문제가 생기면 뒤에 모든 파이프라인에도 문제가 생긴다. 
 =====================================================================
 LangGraph 제안
 1) Node를 정의 (세부 과정)
 2) Edge로 각 노드를 연결
 3) 조건부 엣지를 통해 분기 처리
위와 같은 것이 가능하다면, 순환구조가 가능해짐. 순환구조가 가능해지면, 답변된 문서의 신뢰성을 검증하고 신뢰성이 떨어지면 다시 Retrive를 하는 구조 설계가 가능해짐.

예를들어, 문서를 생성하고 이 생성된 문서를 평가하고 신뢰성 점수를 매긴다. 이 신뢰성 점수가 일정 이하면 다시 질문Query를 생성하거나, Retrieve를 하거나 할 수 있다. 반복되어 신뢰성 점수가 높아지게 되면 최종 답변을 하게 된다.

여기서 중요한점은, Node들은 꼭 LangChain(Agent)가 아니여도 상관 없다. 다른 라이브러리를 써도 좋고, API를 Call 하기만 해도 좋다. 파이썬 코드로만 작성해두어도 상관없다. 
 =====================================================================
LangGraph 특징
1) Node(노드), Edge(엣지), State(상태관리)를 통해 LLM을 활용한 워크플로우에 순환(Cycle) 연산 기능을 통해 쉽게 흐름을 제어
2) RAG 파이프라인의 세부 단계별 흐름제어 가능
3) Human-in-the-loop 필요시 중간 개입하여 다음 단계를 결정
4) Checkpointer:과거 실행 과정에 대한 "수정" & "리플레이" 가능
5) 각 노드의 데이터 전달은 State(딕셔너리 타입)으로 전달
5) 각 노드의 데이터 전달은 State(딕셔너리 타입)으로 전달
5) 각 노드의 데이터 전달은 State(딕셔너리 타입)으로 전달
5) 각 노드의 데이터 전달은 State(딕셔너리 타입)으로 전달
5) 각 노드의 데이터 전달은 State(딕셔너리 타입)으로 전달

